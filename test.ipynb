{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 17:25:24.009084: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-05 17:25:24.023284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741213524.037900   53036 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741213524.042148   53036 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 17:25:24.062455: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Step 1: Load the rules text from the provided file\n",
    "def load_rules(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        rules_text = file.read()\n",
    "    return rules_text\n",
    "\n",
    "\n",
    "def fine_tune_model(model, tokenizer, rules_text):\n",
    "    inputs = tokenizer(rules_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def retrieve_relevant_section(query, vectorizer, rules_vectors, rules_sections):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = np.dot(query_vector, rules_vectors.T).toarray()[0]\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    return rules_sections[most_similar_index]\n",
    "\n",
    "\n",
    "def ask_question(question, vectorizer, rules_vectors, rules_sections, qa_pipeline):\n",
    "    relevant_section = retrieve_relevant_section(question, vectorizer, rules_vectors, rules_sections)\n",
    "    input_text = f\"Context: {relevant_section}\\nQuestion: {question}\\nAnswer:\"\n",
    "    response = qa_pipeline(input_text, max_length=100, num_return_sequences=1)\n",
    "    return response[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_text = load_rules(\"ultimate_frisbee_rules-manual_copy_from_website.txt\")\n",
    "\n",
    "# Step 3: Fine-Tune GPT-2\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[10962,   286, 26714,  ...,   966,    11,   351]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(rules_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (30938 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10962,   286, 26714,  ...,  3747,    13,   198])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(rules_text, return_tensors=\"pt\", truncation=False)[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 176,\n",
       " 0,\n",
       " 3,\n",
       " 133,\n",
       " 7,\n",
       " 26,\n",
       " 72,\n",
       " 57,\n",
       " 36,\n",
       " 6,\n",
       " 55,\n",
       " 48,\n",
       " 98,\n",
       " 45,\n",
       " 154,\n",
       " 26,\n",
       " 13,\n",
       " 38,\n",
       " 13,\n",
       " 9,\n",
       " 14,\n",
       " 13,\n",
       " 16,\n",
       " 12,\n",
       " 18,\n",
       " 10,\n",
       " 22,\n",
       " 20,\n",
       " 115,\n",
       " 57,\n",
       " 15,\n",
       " 23,\n",
       " 17,\n",
       " 36,\n",
       " 33,\n",
       " 34,\n",
       " 16,\n",
       " 19,\n",
       " 27,\n",
       " 18,\n",
       " 25,\n",
       " 33,\n",
       " 24,\n",
       " 13,\n",
       " 15,\n",
       " 13,\n",
       " 20,\n",
       " 10,\n",
       " 21,\n",
       " 43,\n",
       " 15,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 14,\n",
       " 34,\n",
       " 23,\n",
       " 118,\n",
       " 37,\n",
       " 78,\n",
       " 107,\n",
       " 40,\n",
       " 16,\n",
       " 13,\n",
       " 16,\n",
       " 9,\n",
       " 3,\n",
       " 77,\n",
       " 50,\n",
       " 54,\n",
       " 120,\n",
       " 63,\n",
       " 31,\n",
       " 40,\n",
       " 55,\n",
       " 61,\n",
       " 51,\n",
       " 86,\n",
       " 48,\n",
       " 98,\n",
       " 27,\n",
       " 19,\n",
       " 47,\n",
       " 29,\n",
       " 39,\n",
       " 56,\n",
       " 83,\n",
       " 34,\n",
       " 29,\n",
       " 121,\n",
       " 101,\n",
       " 60,\n",
       " 83,\n",
       " 57,\n",
       " 14,\n",
       " 16,\n",
       " 50,\n",
       " 25,\n",
       " 28,\n",
       " 18,\n",
       " 6,\n",
       " 47,\n",
       " 90,\n",
       " 49,\n",
       " 64,\n",
       " 101,\n",
       " 74,\n",
       " 26,\n",
       " 80,\n",
       " 20,\n",
       " 28,\n",
       " 39,\n",
       " 27,\n",
       " 71,\n",
       " 38,\n",
       " 57,\n",
       " 4,\n",
       " 41,\n",
       " 22,\n",
       " 44,\n",
       " 46,\n",
       " 36,\n",
       " 23,\n",
       " 64,\n",
       " 27,\n",
       " 16,\n",
       " 33,\n",
       " 39,\n",
       " 60,\n",
       " 3,\n",
       " 30,\n",
       " 24,\n",
       " 34,\n",
       " 35,\n",
       " 25,\n",
       " 59,\n",
       " 70,\n",
       " 5,\n",
       " 31,\n",
       " 16,\n",
       " 59,\n",
       " 67,\n",
       " 6,\n",
       " 73,\n",
       " 44,\n",
       " 85,\n",
       " 33,\n",
       " 73,\n",
       " 4,\n",
       " 15,\n",
       " 22,\n",
       " 13,\n",
       " 56,\n",
       " 75,\n",
       " 19,\n",
       " 29,\n",
       " 76,\n",
       " 74,\n",
       " 85,\n",
       " 98,\n",
       " 34,\n",
       " 22,\n",
       " 89,\n",
       " 109,\n",
       " 15,\n",
       " 26,\n",
       " 64,\n",
       " 43,\n",
       " 68,\n",
       " 37,\n",
       " 30,\n",
       " 31,\n",
       " 91,\n",
       " 39,\n",
       " 36,\n",
       " 23,\n",
       " 41,\n",
       " 51,\n",
       " 33,\n",
       " 49,\n",
       " 27,\n",
       " 111,\n",
       " 154,\n",
       " 33,\n",
       " 69,\n",
       " 29,\n",
       " 15,\n",
       " 31,\n",
       " 37,\n",
       " 35,\n",
       " 45,\n",
       " 42,\n",
       " 80,\n",
       " 23,\n",
       " 46,\n",
       " 42,\n",
       " 12,\n",
       " 56,\n",
       " 11,\n",
       " 55,\n",
       " 33,\n",
       " 50,\n",
       " 47,\n",
       " 39,\n",
       " 11,\n",
       " 23,\n",
       " 18,\n",
       " 112,\n",
       " 67,\n",
       " 6,\n",
       " 12,\n",
       " 20,\n",
       " 76,\n",
       " 27,\n",
       " 8,\n",
       " 9,\n",
       " 17,\n",
       " 16,\n",
       " 17,\n",
       " 14,\n",
       " 18,\n",
       " 50,\n",
       " 6,\n",
       " 22,\n",
       " 23,\n",
       " 117,\n",
       " 81,\n",
       " 48,\n",
       " 30,\n",
       " 106,\n",
       " 102,\n",
       " 12,\n",
       " 44,\n",
       " 37,\n",
       " 27,\n",
       " 319,\n",
       " 95,\n",
       " 86,\n",
       " 168,\n",
       " 61,\n",
       " 46,\n",
       " 31,\n",
       " 37,\n",
       " 74,\n",
       " 64,\n",
       " 32,\n",
       " 20,\n",
       " 37,\n",
       " 37,\n",
       " 40,\n",
       " 56,\n",
       " 46,\n",
       " 76,\n",
       " 71,\n",
       " 8,\n",
       " 90,\n",
       " 73,\n",
       " 66,\n",
       " 31,\n",
       " 32,\n",
       " 22,\n",
       " 20,\n",
       " 21,\n",
       " 21,\n",
       " 20,\n",
       " 12,\n",
       " 34,\n",
       " 22,\n",
       " 27,\n",
       " 22,\n",
       " 83,\n",
       " 43,\n",
       " 34,\n",
       " 50,\n",
       " 6,\n",
       " 57,\n",
       " 62,\n",
       " 29,\n",
       " 80,\n",
       " 22,\n",
       " 82,\n",
       " 15,\n",
       " 51,\n",
       " 55,\n",
       " 20,\n",
       " 15,\n",
       " 28,\n",
       " 11,\n",
       " 33,\n",
       " 79,\n",
       " 78,\n",
       " 121,\n",
       " 54,\n",
       " 30,\n",
       " 122,\n",
       " 26,\n",
       " 51,\n",
       " 37,\n",
       " 55,\n",
       " 58,\n",
       " 14,\n",
       " 16,\n",
       " 14,\n",
       " 42,\n",
       " 32,\n",
       " 26,\n",
       " 6,\n",
       " 30,\n",
       " 39,\n",
       " 106,\n",
       " 62,\n",
       " 62,\n",
       " 4,\n",
       " 41,\n",
       " 131,\n",
       " 75,\n",
       " 56,\n",
       " 86,\n",
       " 321,\n",
       " 20,\n",
       " 4,\n",
       " 9,\n",
       " 11,\n",
       " 28,\n",
       " 24,\n",
       " 169,\n",
       " 77,\n",
       " 18,\n",
       " 26,\n",
       " 16,\n",
       " 44,\n",
       " 111,\n",
       " 117,\n",
       " 5,\n",
       " 36,\n",
       " 27,\n",
       " 55,\n",
       " 108,\n",
       " 85,\n",
       " 95,\n",
       " 73,\n",
       " 83,\n",
       " 113,\n",
       " 97,\n",
       " 170,\n",
       " 70,\n",
       " 37,\n",
       " 5,\n",
       " 28,\n",
       " 33,\n",
       " 60,\n",
       " 36,\n",
       " 29,\n",
       " 44,\n",
       " 71,\n",
       " 35,\n",
       " 15,\n",
       " 18,\n",
       " 22,\n",
       " 84,\n",
       " 61,\n",
       " 84,\n",
       " 71,\n",
       " 29,\n",
       " 81,\n",
       " 61,\n",
       " 69,\n",
       " 11,\n",
       " 11,\n",
       " 20,\n",
       " 18,\n",
       " 16,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 11,\n",
       " 14,\n",
       " 23,\n",
       " 7,\n",
       " 8,\n",
       " 16,\n",
       " 15,\n",
       " 21,\n",
       " 9,\n",
       " 34,\n",
       " 31,\n",
       " 145,\n",
       " 89,\n",
       " 29,\n",
       " 9,\n",
       " 52,\n",
       " 58,\n",
       " 55,\n",
       " 117,\n",
       " 9,\n",
       " 16,\n",
       " 31,\n",
       " 19,\n",
       " 18,\n",
       " 29,\n",
       " 43,\n",
       " 103,\n",
       " 32,\n",
       " 29,\n",
       " 251,\n",
       " 56,\n",
       " 4,\n",
       " 166,\n",
       " 27,\n",
       " 33,\n",
       " 23,\n",
       " 27,\n",
       " 19,\n",
       " 73,\n",
       " 7,\n",
       " 94,\n",
       " 102,\n",
       " 209,\n",
       " 68,\n",
       " 104,\n",
       " 13,\n",
       " 14,\n",
       " 44,\n",
       " 33,\n",
       " 124,\n",
       " 14,\n",
       " 52,\n",
       " 30,\n",
       " 43,\n",
       " 13,\n",
       " 14,\n",
       " 52,\n",
       " 30,\n",
       " 21,\n",
       " 234,\n",
       " 12,\n",
       " 40,\n",
       " 33,\n",
       " 76,\n",
       " 18,\n",
       " 18,\n",
       " 44,\n",
       " 29,\n",
       " 89,\n",
       " 80,\n",
       " 24,\n",
       " 98,\n",
       " 48,\n",
       " 31,\n",
       " 64,\n",
       " 37,\n",
       " 88,\n",
       " 84,\n",
       " 48,\n",
       " 3,\n",
       " 54,\n",
       " 87,\n",
       " 132,\n",
       " 152,\n",
       " 92,\n",
       " 10,\n",
       " 10,\n",
       " 21,\n",
       " 21,\n",
       " 18,\n",
       " 6,\n",
       " 12,\n",
       " 23,\n",
       " 18,\n",
       " 26,\n",
       " 124,\n",
       " 97,\n",
       " 50,\n",
       " 382,\n",
       " 300,\n",
       " 35,\n",
       " 30,\n",
       " 18,\n",
       " 13,\n",
       " 125,\n",
       " 76,\n",
       " 212,\n",
       " 94,\n",
       " 78,\n",
       " 160,\n",
       " 34,\n",
       " 13,\n",
       " 144,\n",
       " 81,\n",
       " 132,\n",
       " 130,\n",
       " 13,\n",
       " 147,\n",
       " 79,\n",
       " 129,\n",
       " 6,\n",
       " 91,\n",
       " 58,\n",
       " 135,\n",
       " 28,\n",
       " 202,\n",
       " 17,\n",
       " 37,\n",
       " 38,\n",
       " 48,\n",
       " 39,\n",
       " 26,\n",
       " 9,\n",
       " 43,\n",
       " 35,\n",
       " 20,\n",
       " 9,\n",
       " 18,\n",
       " 35,\n",
       " 174,\n",
       " 19,\n",
       " 89,\n",
       " 100,\n",
       " 165,\n",
       " 94,\n",
       " 4,\n",
       " 41,\n",
       " 117,\n",
       " 46,\n",
       " 5,\n",
       " 20,\n",
       " 17,\n",
       " 18,\n",
       " 11,\n",
       " 20,\n",
       " 30,\n",
       " 25,\n",
       " 32,\n",
       " 34,\n",
       " 21,\n",
       " 188,\n",
       " 4,\n",
       " 33,\n",
       " 75,\n",
       " 48,\n",
       " 27,\n",
       " 34,\n",
       " 104,\n",
       " 31,\n",
       " 7,\n",
       " 155,\n",
       " 9,\n",
       " 8,\n",
       " 31,\n",
       " 24,\n",
       " 31,\n",
       " 32,\n",
       " 23,\n",
       " 14,\n",
       " 44,\n",
       " 53,\n",
       " 23,\n",
       " 30,\n",
       " 31,\n",
       " 22,\n",
       " 14,\n",
       " 36,\n",
       " 38,\n",
       " 59,\n",
       " 27,\n",
       " 37,\n",
       " 26,\n",
       " 11,\n",
       " 21,\n",
       " 37,\n",
       " 44,\n",
       " 44,\n",
       " 35,\n",
       " 24,\n",
       " 9,\n",
       " 67,\n",
       " 40,\n",
       " 8,\n",
       " 7,\n",
       " 40,\n",
       " 32,\n",
       " 57,\n",
       " 26,\n",
       " 44,\n",
       " 37,\n",
       " 6,\n",
       " 86,\n",
       " 48,\n",
       " 7,\n",
       " 32,\n",
       " 32,\n",
       " 10,\n",
       " 27,\n",
       " 10,\n",
       " 40,\n",
       " 7,\n",
       " 45,\n",
       " 10,\n",
       " 29,\n",
       " 40,\n",
       " 31,\n",
       " 39,\n",
       " 4,\n",
       " 24,\n",
       " 20,\n",
       " 19,\n",
       " 37,\n",
       " 33,\n",
       " 14,\n",
       " 31,\n",
       " 50,\n",
       " 26,\n",
       " 56,\n",
       " 31,\n",
       " 39,\n",
       " 12,\n",
       " 35,\n",
       " 73,\n",
       " 44,\n",
       " 12,\n",
       " 35,\n",
       " 70,\n",
       " 66,\n",
       " 39,\n",
       " 13,\n",
       " 27,\n",
       " 43,\n",
       " 51,\n",
       " 20,\n",
       " 25,\n",
       " 44,\n",
       " 12,\n",
       " 21,\n",
       " 36,\n",
       " 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_line = [tokenizer(line) for line in rules_text.split('\\n')]\n",
    "num_tokens_per_line = [len(tokens['input_ids']) for tokens in tokens_per_line]\n",
    "num_tokens_per_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction from PDF using PyMuPDF. Good but has newlines in paragraphs.\n",
    "\n",
    "# Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Step 1: Extract text from the PDF\n",
    "pdf_path = \"Official-Rules-of-Ultimate-2024-2025.pdf\"\n",
    "rules_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Save the extracted text to a file\n",
    "with open(\"ultimate_frisbee_rules-pdf_extraction.txt\", \"w\") as file:\n",
    "    file.write(rules_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rules have been successfully extracted and saved to 'cleaned_ultimate_frisbee_rules.txt'.\n"
     ]
    }
   ],
   "source": [
    "# Extraction from HTML using BeautifulSoup. Not so great.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load the HTML content from the file\n",
    "with open('ultimate_frisbee_rules.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Extract the main content of the rules\n",
    "rules_content = soup.find('div', {'id': 'rules-of-ultimate'}).get_text(separator='\\n')\n",
    "\n",
    "# Clean the extracted text\n",
    "def clean_text(text):\n",
    "    # Replace multiple newlines with a single newline\n",
    "    text = text.replace('\\n\\n', '\\n')\n",
    "    \n",
    "    # Replace newlines in the middle of paragraphs with a space\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Ensure paragraphs are separated by a single newline\n",
    "    text = text.replace('. ', '.\\n')\n",
    "    \n",
    "    return text\n",
    "\n",
    "cleaned_rules_content = clean_text(rules_content)\n",
    "\n",
    "# Save the cleaned rules to a text file\n",
    "with open('ultimate_frisbee_rules-html_extraction.txt', 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(cleaned_rules_content)\n",
    "\n",
    "print(\"The rules have been successfully extracted and saved to 'cleaned_ultimate_frisbee_rules.txt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU test (pytorch)\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Define a simple matrix multiplication task\n",
    "def gpu_test():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create random tensors\n",
    "    a = torch.randn(10000, 10000, device=device)\n",
    "    b = torch.randn(10000, 10000, device=device)\n",
    "\n",
    "    # Perform matrix multiplication\n",
    "    start_time = time.time()\n",
    "    c = torch.matmul(a, b)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Matrix multiplication completed in {end_time - start_time} seconds\")\n",
    "\n",
    "for i in range(10000):\n",
    "    gpu_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 15:00:32.762867: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-05 15:00:32.772080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741204832.781773   12855 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741204832.784905   12855 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 15:00:32.795874: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "TensorFlow GPU details:\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# GPU test (tensorflow)\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Check if TensorFlow can access the GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "\n",
    "if physical_devices:\n",
    "    print(\"TensorFlow GPU details:\")\n",
    "    for gpu in physical_devices:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPUs detected by TensorFlow.\")\n",
    "\n",
    "# Define a simple matrix multiplication task\n",
    "def gpu_test():\n",
    "    device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create random tensors\n",
    "    with tf.device(device):\n",
    "        a = tf.random.normal([10000, 10000])\n",
    "        b = tf.random.normal([10000, 10000])\n",
    "\n",
    "        # Perform matrix multiplication\n",
    "        start_time = time.time()\n",
    "        c = tf.matmul(a, b)\n",
    "        end_time = time.time()\n",
    "\n",
    "    print(f\"Matrix multiplication completed in {end_time - start_time} seconds\")\n",
    "\n",
    "for i in range(10000):\n",
    "    gpu_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env-2025-03-03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
