{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rules(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        rules_text = file.read()\n",
    "    return rules_text\n",
    "\n",
    "def preprocess_document(document):\n",
    "    # Split document into lines\n",
    "    chunks = document.split('\\n')\n",
    "    # Remove any empty lines\n",
    "    chunks = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
    "    return chunks\n",
    "\n",
    "# Load and preprocess the document\n",
    "document = load_rules(\"ultimate_frisbee_rules-manual_copy_from_website-edited.txt\")\n",
    "chunks = preprocess_document(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Vectorize the chunks\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(chunks)\n",
    "\n",
    "# Store vectors and chunks\n",
    "index = {i: chunk for i, chunk in enumerate(chunks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.D.5. explain their viewpoint clearly and concisely;', '7.E.3. After the spirit timeout:', '20.E. If a novice player commits an infraction out of sincere ignorance of the rules, it should be common practice to stop play and explain the infraction.', '2.H. In the case where a novice player commits an infraction out of ignorance of the rules, experienced players are obliged to explain the infraction and clarify what should happen.', '15.A.5.b. Specific Rules:']\n"
     ]
    }
   ],
   "source": [
    "def retrieve_relevant_chunks(query, vectorizer, X, index, top_n=5):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vec, X).flatten()\n",
    "    relevant_indices = np.argsort(similarities, axis=0)[-top_n:][::-1]\n",
    "    return [index[i] for i in relevant_indices]\n",
    "\n",
    "query = \"Explain the timeout rules\"\n",
    "relevant_chunks = retrieve_relevant_chunks(query, vectorizer, X, index)\n",
    "print(relevant_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 16:15:11.547355: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-06 16:15:11.660686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741295711.714132   39186 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741295711.727860   39186 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 16:15:11.816329: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 16:44:37.508183: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-06 16:44:37.750401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741297477.837799   45864 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741297477.862013   45864 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 16:44:38.074791: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Preprocessing took 0.00 seconds\n",
      "Loading the retrieval model took 2.07 seconds\n",
      "Vectorizing the chunks took 0.66 seconds\n",
      "Indexing took 0.00 seconds\n",
      "Loading the generation model took 25.36 seconds\n",
      "Setting pad_token_id took 0.00 seconds\n",
      "Retrieving relevant chunks took 0.03 seconds\n",
      "['15.A.1. The stall count consists of announcing “stalling” and counting from one to ten loudly enough for the thrower to hear.', '15.A.5. If a stall count is interrupted by a call, the thrower and marker are responsible for agreeing on the correct count before the check. The count reached is the last number fully uttered by the marker before the call. The count is resumed with the word “stalling” followed by the number listed below:', '7.D.4.a.2. If the technical timeout stopped play, the count resumes at the stall count reached plus one, or at six if over five.', '15.A.2.b. However, unless 15.A.2.a applies, the stall count may not be initiated or resumed before a pivot is established:', '15.B.6.c. If this (15.B.6.b) occurs in the same possession following a contested stall (either due to 15.B.6.a or 15.A.3.b), the stall count resumes at six.']\n",
      "Generating the response took 98.61 seconds\n",
      "Andrew's favorite color is violet. What is Andrew's favorite color?\n",
      "\n",
      "A:\n",
      "\n",
      "I think the answer is\n",
      "\n",
      " violet\n",
      "\n",
      "because\n",
      "\n",
      " the color violet is the color of the sky, and the sky is violet.\n",
      "\n",
      "A:\n",
      "\n",
      "I think the answer is\n",
      "\n",
      " violet\n",
      "\n",
      "because\n",
      "\n",
      " the color violet is the color of the sky, and the sky is violet.\n",
      "\n",
      "A:\n",
      "\n",
      "I think the answer is\n",
      "\n",
      " violet\n",
      "\n",
      "because\n",
      "\n",
      " the color violet is the color of the sky, and the sky is violet.\n",
      "\n",
      "I think the answer is\n",
      "\n",
      " violet\n",
      "\n",
      "because\n",
      "\n",
      " the color violet is the color of the sky, and the sky is violet.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import time\n",
    "\n",
    "# model_name = 'gpt2-xl'  # this is the largest GPT-2 model from OpenAI and is open source\n",
    "model_name = \"EleutherAI/gpt-neo-2.7B\"  # best GPT-related model for my laptop\n",
    "# model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'  # works, best deepseek model I can get working\n",
    "# query = \"Explain the timeout rules\"\n",
    "query = \"What is the stall count?\"\n",
    "use_gpu_if_available = True\n",
    "\n",
    "device = torch.device(\"cuda\" if use_gpu_if_available and torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def load_rules(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        rules_text = file.read()\n",
    "    return rules_text\n",
    "\n",
    "def preprocess_document(document):\n",
    "    # Split document into lines\n",
    "    chunks = document.split('\\n')\n",
    "    # Remove any empty lines\n",
    "    chunks = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
    "    return chunks\n",
    "\n",
    "def retrieve_relevant_chunks(query, model_retriever, chunk_embeddings, index, top_n=5):\n",
    "    query_embedding = model_retriever.encode(query, convert_to_tensor=True, device=device)\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, chunk_embeddings)[0]\n",
    "    similarities = similarities.cpu().numpy()  # Move to CPU and convert to NumPy array\n",
    "    relevant_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "    return [index[i] for i in relevant_indices]\n",
    "\n",
    "def generate_response(query, relevant_chunks, model_generator, tokenizer):\n",
    "    # Combine the relevant chunks into a single context\n",
    "    context = \" \".join(relevant_chunks)\n",
    "    # input_text = f\"Query: Be concise. {query}\\nContext: {context}\\nAnswer:\"\n",
    "    input_text = 'Andrew\\'s favorite color is violet. What is Andrew\\'s favorite color?'\n",
    "    inputs = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "    attention_mask = inputs.ne(tokenizer.pad_token_id).long()  # Create attention mask\n",
    "    outputs = model_generator.generate(\n",
    "        inputs,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=500,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Load and preprocess the document\n",
    "start_time = time.time()\n",
    "document = load_rules(\"ultimate_frisbee_rules-manual_copy_from_website-edited.txt\")\n",
    "chunks = preprocess_document(document)\n",
    "print(f\"Preprocessing took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Load the model\n",
    "start_time = time.time()\n",
    "model_retriever = SentenceTransformer('all-MiniLM-L6-v2', device=device)  # device=device probably unnecessary for the retriever\n",
    "print(f\"Loading the retrieval model took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Vectorize the chunks\n",
    "start_time = time.time()\n",
    "chunk_embeddings = model_retriever.encode(chunks, convert_to_tensor=True, device=device)\n",
    "print(f\"Vectorizing the chunks took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Store vectors and chunks\n",
    "start_time = time.time()\n",
    "index = {i: chunk for i, chunk in enumerate(chunks)}\n",
    "print(f\"Indexing took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "start_time = time.time()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_generator = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "print(f\"Loading the generation model took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Set pad_token_id to eos_token_id\n",
    "start_time = time.time()\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "print(f\"Setting pad_token_id took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "relevant_chunks = retrieve_relevant_chunks(query, model_retriever, chunk_embeddings, index)\n",
    "print(f\"Retrieving relevant chunks took {time.time() - start_time:.2f} seconds\")\n",
    "print(relevant_chunks)\n",
    "\n",
    "start_time = time.time()\n",
    "response = generate_response(query, relevant_chunks, model_generator, tokenizer)\n",
    "print(f\"Generating the response took {time.time() - start_time:.2f} seconds\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the stall count?\n",
      "Context: 15.A.1. The stall count consists of announcing “stalling” and counting from one to ten loudly enough for the thrower to hear. 15.A.5. If a stall count is interrupted by a call, the thrower and marker are responsible for agreeing on the correct count before the check. The count reached is the last number fully uttered by the marker before the call. The count is resumed with the word “stalling” followed by the number listed below: 7.D.4.a.2. If the technical timeout stopped play, the count resumes at the stall count reached plus one, or at six if over five. 15.A.2.b. However, unless 15.A.2.a applies, the stall count may not be initiated or resumed before a pivot is established: 15.B.6.c. If this (15.B.6.b) occurs in the same possession following a contested stall (either due to 15.B.6.a or 15.A.3.b), the stall count resumes at six.\n",
      "Answer:\n",
      "Context: 15.B.6.b. The technical timeout stopped play. 15.B.6.c. If this (15.B.6.b) occurs in the same possession following a contested stall (either due to 15.B.6.a or 15.A.3.b), the stall count resumes at six.\n",
      "Answer:\n",
      "Context: 15.B.6.b. The technical timeout stopped play. 15.B.6.c. If this (15.B.6.b) occurs in the same possession following a contested stall (either due to 15.B.6.a or 15.A.3.b), the stall count resumes at six.\n",
      "Answer:\n",
      "Context: 15.B.6.b. The technical timeout stopped play. 15.B.6.c. If this (15.B.6.b) occurs in the same possession following a contested stall (either due to 15.B.6.a or 15.A.3.b), the stall count resumes at six.\n",
      "Answer:\n",
      "Context: 15.B.6.b. The technical timeout stopped play. 15.B.6.c. If this (15.B.6.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Explain the timeout rules\n",
      "Context: 7.B.2. Any player may call a timeout after a goal is scored and before both teams have signaled readiness to start play. Time limit counts between points are suspended for 70 seconds. A timeout may not be called between a re-pull call and the ensuing pull. 7.A. A timeout stops play and suspends time limit counts. 7.C.2. The timeout is retroactive to the time of the injury, unless the injured player chooses to continue play before the timeout is called, in which case, the timeout begins at the time of the call. If the disc is in the air or the thrower is in the act of throwing at the time of the injury or of the call when the player has continued play, the timeout begins when the play is completed. 7.C.7.a. This timeout takes effect when the call is made (i.e., is not retroactive to the time of injury). If the disc is in the air or the thrower is in the act of throwing at the time of the call, the timeout begins when the play is completed. However, the disc is returned to the thrower if avoiding potential contact with the bleeding player is determined to have affected the play. 7.C. Injury Timeout: A timeout called for a player injury. During an injury timeout, the health and safety of the injured player are of primary concern.\n",
      "Answer: 7.C.7.a. This timeout takes effect when the call is made (i.e., is not retroactive to the time of injury). If the disc is in the air or the thrower is in the act of throwing at the time of the injury or of the call when the player has continued play, the timeout begins when the play is completed. However, the disc is returned to the thrower if avoiding potential contact with the bleeding player is determined to have affected the play. 7.C.8. A player may not call a timeout during a time out. 7.C.9. A player may not call a timeout during a time out if the disc is in the air or the thrower is in the act of throwing at the time of the injury or of the call when the player has continued play. 7.C.10. A player may not call a timeout during a time out if the disc is in the air or the thrower is in the act of\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env-2025-03-03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
